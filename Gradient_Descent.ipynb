{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f701f51a",
   "metadata": {},
   "source": [
    "batch ak shat shab data weigth and bias update and in smoth and also fast also use vectrization meand use dot product in stant of for loop but one drow back is all data come togethet in ram and if 10 crores data come together than it is not posible in this no zig zag if thay stop on local minima than thay can not come out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77ba397",
   "metadata": {},
   "source": [
    "SGD is do on all single data and it is slow but fast solving the loss and it have random data before in updting weights and baid so thay have some zig zag this is advantage and also disvantage some time come in local minima than thay outmateic come out bgd > mbgd > sgd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffe2b89",
   "metadata": {},
   "source": [
    "mbgd is me total epoch hote he or pure data ko batches me convert kar dete he or fir har betch ke liye kar te or is me also vectrization hota he or is zig zag bhi kam hota he is liye ye bgd or sgd dono se acha hota he or ye shawal he ki batch ko 2 ke multipal me hi ku dete ho vo ram ka optimize use kar ta he is lie vo binary  or keras bhi optimaize use kar ta he or nahi koi bhi batch number de shak te ho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7402cf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9da23022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " GPU availabe: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    print(\" GPU availabe:\", gpus)\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "else:\n",
    "    print(\" GPU not found running on CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9466739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16512, 8)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = fetch_california_housing()\n",
    "\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d15c96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78d1df23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(optimizer, name):\n",
    "    print(f\"\\n Training using: {name}\")\n",
    "\n",
    "    model = create_model()\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=20,\n",
    "        batch_size=32, #mini - batch gd\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    test_loss, test_mae = model.evaluate(X_test, y_test, verbose = 0)\n",
    "\n",
    "    print(f\"Test MSE: {test_loss:.4f}\")\n",
    "    print(f\"Test MAE: {test_mae:.4f}\")\n",
    "    \n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a3ef64",
   "metadata": {},
   "source": [
    "Batch / Mini-Batch Gradient Descent (SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25df8df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training using: SGD (Mini-Batch Gradient Descent)\n",
      "Test MSE: 0.3247\n",
      "Test MAE: 0.3981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18cdbe35d30>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "    name=\"SGD (Mini-Batch Gradient Descent)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "073975ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training using: SGD with Momentum\n",
      "Test MSE: 1.3104\n",
      "Test MAE: 0.9033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18cebd38be0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(\n",
    "    optimizer=tf.keras.optimizers.SGD(\n",
    "        learning_rate=0.01,\n",
    "        momentum=0.9\n",
    "    ),\n",
    "    name=\"SGD with Momentum\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f0cfa4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training using: Nesterov Gradient Descent\n",
      "Test MSE: nan\n",
      "Test MAE: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18cf8ee53a0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(\n",
    "    optimizer=tf.keras.optimizers.SGD(\n",
    "        learning_rate=0.01,\n",
    "        momentum=0.9,\n",
    "        nesterov=True\n",
    "    ),\n",
    "    name=\"Nesterov Gradient Descent\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0e28cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training using: AdaGrad\n",
      "Test MSE: 0.3049\n",
      "Test MAE: 0.3905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18d043780d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(\n",
    "    optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.05),\n",
    "    name=\"AdaGrad\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "241b86c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training using: RMSProp\n",
      "Test MSE: 0.2989\n",
      "Test MAE: 0.3746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18d043af280>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(\n",
    "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
    "    name=\"RMSProp\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe2f1282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training using: Adam Optimizer\n",
      "Test MSE: 0.2977\n",
      "Test MAE: 0.3789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18d1331c640>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    name=\"Adam Optimizer\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553e1ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
