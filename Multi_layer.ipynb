{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df750646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "X = [\n",
    "    [0,0],\n",
    "    [0,1],\n",
    "    [1,0],\n",
    "    [1,1]\n",
    "]\n",
    "\n",
    "y = [0,1,1,0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "842d7793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    return math.tanh(x)\n",
    "\n",
    "def tanh_derivative(x):\n",
    "    return 1 - math.tanh(x)**2\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 +math.exp(-x))\n",
    "\n",
    "def sigmoid_deerivative(x):\n",
    "    s = sigmoid(x)\n",
    "    return s * (1 - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65d84a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = [\n",
    "    [random.uniform(1,-1), random.uniform(1,-1)],\n",
    "    [random.uniform(1,-1), random.uniform(1,-1)],\n",
    "]\n",
    "b1 = [random.uniform(1,-1), random.uniform(1,-1)]\n",
    "\n",
    "w2 = [random.uniform(1,-1), random.uniform(1,-1)]\n",
    "\n",
    "b2 = random.uniform(-1,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a487a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "lr = 0.1\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(len(X)):\n",
    "        x1, x2 = X[i]\n",
    "\n",
    "        h1_in = x1*w1[0][0] + x2*w1[0][1] +b1[0]\n",
    "        h2_in = x1*w1[1][0] + x2*w1[1][1] +b1[1]\n",
    "\n",
    "        h1 = np.tanh(h1_in)\n",
    "        h2 = np.tanh(h2_in)\n",
    "\n",
    "        out_in = h1*w2[0] + h2*w2[1] + b2\n",
    "        out = sigmoid(out_in)\n",
    "\n",
    "        error = y[i] - out\n",
    "\n",
    "        d_out = error * out * (1 - out)\n",
    "\n",
    "        d_h1 = d_out * w2[0] * tanh_derivative(h1_in)\n",
    "        d_h2 = d_out * w2[1] * tanh_derivative(h2_in)\n",
    "\n",
    "        w2[0] += lr * d_out * h1\n",
    "        w2[0] += lr * d_out * h2\n",
    "        b2 += lr * d_out\n",
    "\n",
    "        w1[0][0] = lr * d_h1 * x1\n",
    "        w1[0][1] = lr * d_h1 * x2\n",
    "        w1[1][0] = lr * d_h2 * x1\n",
    "        w1[1][1] = lr * d_h2 * x2\n",
    "\n",
    "        b1[0] += lr * d_h1\n",
    "        b1[1] += lr * d_h2\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "734d0470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Predictions:\n",
      "[0, 0] --> 0\n",
      "[0, 1] --> 0\n",
      "[1, 0] --> 0\n",
      "[1, 1] --> 0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFinal Predictions:\")\n",
    "for x in X:\n",
    "    x1, x2 = x\n",
    "\n",
    "    h1 = tanh(x1*w1[0][0] + x2*w1[0][1] + b1[0])\n",
    "    h2 = tanh(x1*w1[1][0] + x2*w1[1][1] + b1[1])\n",
    "\n",
    "    out = sigmoid(h1*w2[0] + h2*w2[1] + b2)\n",
    "\n",
    "    print(x, \"-->\", 1 if out > 0.5 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83aff49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.5009 - accuracy: 0.8623 - val_loss: 0.2337 - val_accuracy: 0.9342\n",
      "Epoch 2/15\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.2069 - accuracy: 0.9403 - val_loss: 0.1730 - val_accuracy: 0.9480\n",
      "Epoch 3/15\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1563 - accuracy: 0.9546 - val_loss: 0.1448 - val_accuracy: 0.9570\n",
      "Epoch 4/15\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1283 - accuracy: 0.9624 - val_loss: 0.1283 - val_accuracy: 0.9623\n",
      "Epoch 5/15\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1083 - accuracy: 0.9679 - val_loss: 0.1168 - val_accuracy: 0.9669\n",
      "Epoch 6/15\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0917 - accuracy: 0.9736 - val_loss: 0.1095 - val_accuracy: 0.9679\n",
      "Epoch 7/15\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0802 - accuracy: 0.9765 - val_loss: 0.0997 - val_accuracy: 0.9704\n",
      "Epoch 8/15\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0711 - accuracy: 0.9789 - val_loss: 0.0942 - val_accuracy: 0.9722\n",
      "Epoch 9/15\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0634 - accuracy: 0.9812 - val_loss: 0.0975 - val_accuracy: 0.9709\n",
      "Epoch 10/15\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0561 - accuracy: 0.9837 - val_loss: 0.0988 - val_accuracy: 0.9721\n",
      "Epoch 11/15\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0501 - accuracy: 0.9856 - val_loss: 0.0966 - val_accuracy: 0.9712\n",
      "Epoch 12/15\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0460 - accuracy: 0.9866 - val_loss: 0.0877 - val_accuracy: 0.9736\n",
      "Epoch 13/15\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0418 - accuracy: 0.9875 - val_loss: 0.0933 - val_accuracy: 0.9728\n",
      "Epoch 14/15\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0367 - accuracy: 0.9893 - val_loss: 0.0883 - val_accuracy: 0.9740\n",
      "Epoch 15/15\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0334 - accuracy: 0.9905 - val_loss: 0.0885 - val_accuracy: 0.9745\n",
      "313/313 [==============================] - 0s 616us/step - loss: 0.0885 - accuracy: 0.9745\n",
      "Test Accuracy: 0.9745000004768372\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Actual number: 5\n",
      "Predicted number: 5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    tf.keras.layers.Dense(units=64,activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(units=64,activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(units=10,activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics=\"accuracy\"\n",
    ")\n",
    "\n",
    "prediction = model.fit(x_train,y_train,validation_data=(x_test,y_test),batch_size=256,epochs=15)\n",
    "\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "actual = y_train[0]\n",
    "pred = model.predict(x_train[:1])\n",
    "predicted = int(tf.argmax(pred, axis=1)[0])\n",
    "\n",
    "print(\"Actual number:\", actual)\n",
    "print(\"Predicted number:\", predicted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "513663af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 841us/step - loss: 2.6506 - accuracy: 0.8460\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 2s 826us/step - loss: 0.4305 - accuracy: 0.9021\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 2s 830us/step - loss: 0.2890 - accuracy: 0.9257\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 2s 837us/step - loss: 0.2559 - accuracy: 0.9350\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 2s 820us/step - loss: 0.2218 - accuracy: 0.9422\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten,Dense\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28,28)),\n",
    "    tf.keras.layers.Dense(units=128,activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10,activation=\"softmax\")\n",
    "])\n",
    "\n",
    "\n",
    "(x_train,y_train), (x_test,y_test) = mnist.load_data()\n",
    "print()\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit(x_train,y_train,epochs=5,batch_size=32,verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cdd989bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND gate outputs: [0, 0, 0, 1]\n",
      "OR gate outputs: [0, 1, 1, 1]\n",
      "NOT gate outputs: [1, 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Mcculloch:\n",
    "    def __init__(self, weights,threshold):\n",
    "        self.weights = np.array(weights)\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def activation(self, inputs):\n",
    "        inputs = np.array(inputs)\n",
    "        weighted_sum = np.sum(inputs * self.weights)\n",
    "        return 1 if weighted_sum >= self.threshold else 0\n",
    "    \n",
    "and_neuron = Mcculloch(weights=[1,1], threshold=2)\n",
    "or_neuron = Mcculloch(weights=[1,1], threshold=1)\n",
    "not_neuron = Mcculloch(weights=[-1], threshold=0)\n",
    "\n",
    "inputs_binary = [(0,0), (0, 1), (1, 0), (1, 1)]\n",
    "input_unary = [(0,), (1,)]\n",
    "\n",
    "print(\"AND gate outputs:\", [and_neuron.activation(x) for x in inputs_binary])\n",
    "print(\"OR gate outputs:\", [or_neuron.activation(x) for x in inputs_binary])\n",
    "print(\"NOT gate outputs:\", [not_neuron.activation(x) for x in input_unary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe2ec98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
